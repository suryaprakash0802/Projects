Step 1: Set Up a Multi-Node Kubernetes Cluster on AWS EC2
## Launch EC2 Instances:

- Launch the required number of EC2 instances (e.g., 1 master node and 2 worker nodes) on AWS.
- Ensure instances are in the same VPC and security groups allow necessary ports (e.g., 6443 for Kubernetes API server, 10250 for kubelet API, 30000-32767 for NodePort services).

## Install Docker on Each Node:

sudo apt update
sudo apt install -y docker.io
sudo systemctl enable docker
sudo systemctl start docker

## Install Kubernetes Tools (kubectl, kubeadm, kubelet) on Each Node:

sudo apt update
sudo apt install -y apt-transport-https ca-certificates curl
sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

##Initialize the Kubernetes Master Node:
## On the master node, run:
sudo kubeadm init --pod-network-cidr=192.168.0.0/16

## Set up the kubeconfig for the master node user:
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

## Install a Pod Network Add-On:
## On the master node, install a network add-on (e.g., Calico):
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

## Join Worker Nodes to the Cluster:
## On the master node, get the join command:
kubeadm token create --print-join-command

## Run the join command on each worker node.

Step 2: Deploy Microservices on Kubernetes

## Create Kubernetes Manifests for Each Microservice:
- Define Deployment, Service, and ConfigMap for each microservice root directory: 

## microservice-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: microservice
  labels:
    app: microservice
spec:
  replicas: 3
  selector:
    matchLabels:
      app: microservice
  template:
    metadata:
      labels:
        app: microservice
    spec:
      containers:
      - name: microservice
        image: microservice-image
        ports:
        - containerPort: 80

## microservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: microservice
spec:
  selector:
    app: microservice
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: NodePort

## Apply the Manifests to the Cluster:

kubectl apply -f microservice-deployment.yaml
kubectl apply -f microservice-service.yaml

Step 3: Manage Network and Resource Allocation
## Troubleshoot Network Issues:

- Use kubectl get pods -o wide to check pod IPs and status.
- Use kubectl logs <pod-name> to check logs for errors.
- Check network policies if using any network policy management.
- Optimize Resource Allocation:

## Define resource requests and limits in your deployment manifests.

spec:
  containers:
  - name: microservice
    image: microservice-image
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"

## Monitor Cluster Health:

## Install Kubernetes Dashboard or use tools like Prometheus and Grafana for monitoring.

## Install Kubernetes Dashboard

kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml

Step 4: Continuous Integration and Deployment

## Set Up a CI/CD Pipeline:
## Use Jenkins, GitLab CI, or another CI/CD tool to automate builds and deployments.

## Jenkins Pipeline:

pipeline {
    agent any
    stages {
        stage('Build') {
            steps {
                sh 'docker build -t microservice-image .'
            }
        }
        stage('Push') {
            steps {
                withCredentials([string(credentialsId: 'docker-hub-password', variable: 'DOCKER_HUB_PASSWORD')]) {
                    sh 'echo $DOCKER_HUB_PASSWORD | docker login -u suryaprakash --password-stdin'
                    sh 'docker push microservice-image'
                }
            }
        }
        stage('Deploy') {
            steps {
                kubectlDeploy(configs: 'k8s/microservice-deployment.yaml')
                kubectlDeploy(configs: 'k8s/microservice-service.yaml')
            }
        }
    }
}

Step 5: Maintenance and Scaling

## Scale Applications:
##Scale up or down as needed:
kubectl scale deployment microservice --replicas=5

## Rolling Updates:
## Deploy updates without downtime:
kubectl set image deployment/microservice microservice=microservice-image2

## Cluster Autoscaling:

## Set up the Kubernetes Cluster Autoscaler to automatically adjust the number of nodes.

## Install Cluster Autoscaler on AWS:
kubectl apply -f https://github.com/kubernetes/autoscaler/releases/download/cluster-autoscaler-1.20.0/cluster-autoscaler-autodiscover.yaml
